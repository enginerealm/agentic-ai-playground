{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563071cb",
   "metadata": {},
   "source": [
    "## The first big project - Professionally You!\n",
    "## And, Tool use.\n",
    "\n",
    "## But first: introducing MailGun\n",
    "I am using MailGun to send email notifications to my noreply email\n",
    "\n",
    "- Go to https://www.mailgun.com/\n",
    "- Signup for free\n",
    "- create API Key using their SandBox Domain\n",
    "- Add recipients in the recipients list. Recipients will need to agree to receive email notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_client = OpenAI()\n",
    "gemini_openai_client = OpenAI(api_key=os.getenv(\"GEMINI_API_KEY\"), base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "openai_model_name = \"gpt-4o-mini\"\n",
    "gemini_model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "error_send_email= \"Error sending email notification!\"\n",
    "success_send_email= \"Email notification successful!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81bdcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MailGun API to send email notifications\n",
    "def send_mailgun_email_notification(subject, body):\n",
    "    return requests.post(\n",
    "        f\"https://api.mailgun.net/v3/{os.getenv('MAIL_GUN_DOMAIN')}/messages\",\n",
    "        auth=(\"api\", os.getenv('MAIL_GUN_API_KEY')),\n",
    "        data={\n",
    "            \"from\": os.getenv('MAIL_GUN_FROM_EMAIL'),\n",
    "            \"to\": os.getenv('MAIL_GUN_TO_EMAIL'),\n",
    "            \"subject\": subject,\n",
    "            \"text\": body\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42052f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MailGun API\n",
    "send_mailgun_email_notification(\n",
    "    subject=\"Hello VK Avatar\",\n",
    "    body=\"Hey Varun, Notebook Setup Job completed successfully!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4705cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Notify When User Wants to Get in Touch\n",
    "\n",
    "def notify_user_interest(user_name, user_email, message):\n",
    "    subject = f\"[Contact Request] {user_name} wants to get in touch\"\n",
    "    body = f\"\"\"Hi Varun,\n",
    "    \n",
    "        You have a new contact request from your AI Agent Avatar website:\n",
    "        \n",
    "            Name: {user_name}\n",
    "            Email: {user_email}\n",
    "            Message:\n",
    "            {message}\n",
    "        \n",
    "        — AI Avatar Bot\"\"\"\n",
    "\n",
    "    try:\n",
    "        send_mailgun_email_notification(subject, body)\n",
    "    except Exception as e:\n",
    "        print(f\"[Contact Request] Error sending email: {e}\")\n",
    "        return error_send_email\n",
    "\n",
    "    return success_send_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69d18f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Notify When Agent Cannot Answer a Question\n",
    "\n",
    "def notify_agent_failure(user_question, agent_response):\n",
    "    subject = \"[Unanswered Question] Agent Avatar could not respond\"\n",
    "    body = f\"\"\"Hi Varun,\n",
    "        Your AI Agent Avatar couldn't confidently answer a user's question.\n",
    "        \n",
    "        User Question:\n",
    "        {user_question}\n",
    "        \n",
    "        Agent's Attempted Response:\n",
    "        {agent_response}\n",
    "        \n",
    "        You might want to update the knowledge base or manually follow up.\n",
    "        \n",
    "        — AI Avatar Bot\"\"\"\n",
    "\n",
    "    try:\n",
    "        send_mailgun_email_notification(subject, body)\n",
    "    except Exception as e:\n",
    "        print(f\"[Contact Request] Error sending email: {e}\")\n",
    "        return error_send_email\n",
    "\n",
    "    return success_send_email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2ff0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool JSON: Notify When a User Wants to Get in Touch\n",
    "\n",
    "notify_user_interest_tool_json = {\n",
    "  \"name\": \"notify_user_interest\",\n",
    "  \"description\": \"Send an email to me when a visitor wants to get in touch.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"user_name\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The full name of the visitor trying to reach out.\"\n",
    "      },\n",
    "      \"user_email\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The visitor's email address.\"\n",
    "      },\n",
    "      \"message\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The message the visitor wants to send to Varun.\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"user_name\", \"user_email\", \"message\"]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0e404a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool JSON: Notify When Agent Cannot Answer a Question\n",
    "\n",
    "notify_agent_failure_tool_json = {\n",
    "  \"name\": \"notify_agent_failure\",\n",
    "  \"description\": \"Notify me that the agent could not answer a user's question.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"user_question\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The question asked by the visitor.\"\n",
    "      },\n",
    "      \"agent_response\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The agent's attempted or fallback response.\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"user_question\", \"agent_response\"]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "25b04aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool_spec array\n",
    "\n",
    "tool_spec = [ \n",
    "    {\"type\": \"function\", \"function\": notify_user_interest_tool_json}, \n",
    "    {\"type\": \"function\", \"function\": notify_agent_failure_tool_json} \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e007af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can take a list of tool calls, and run them. This is the IF statement!!\n",
    "\n",
    "\"\"\"\n",
    "Here’s what happens step-by-step:\n",
    "\n",
    "    1. User sends a message in Chatbox.\n",
    "    2. LLM/AI_Agent chooses a tool to call.\n",
    "    3. We (Python Script) receive a message like:\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": \"tool_call_id_xyz123\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"notify_user_interest\",\n",
    "                    \"arguments\": \"{ \\\"user_name\\\": \\\"John Doe\\\", \\\"user_email\\\": \\\"john@example.com\\\", \\\"message\\\": \\\"I want to connect.\\\" }\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    4. We run the tool notify_user_interest() with the arguments { \"user_name\": \"John Doe\", \"user_email\": \"john@example.com\", \"message\": \"I want to connect.\" }\n",
    "    5. We return the result to the LLM\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Notification sent successfully.\",\n",
    "            \"tool_call_id\": \"tool_call_id_xyz123\"\n",
    "        }\n",
    "\n",
    "    6. LLM/AI_Agent sees the result and can continue with the conversation\n",
    "\"\"\"\n",
    "\n",
    "def handle_tool_calls_with_if_else(tool_calls):\n",
    "    respond_to_agent_tool_calls = []\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        tool_arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: Name: {tool_name}, Arguments: {tool_arguments}\", flush=True)\n",
    "\n",
    "        # THE BIG IF-ELSE!!!\n",
    "        if tool_name == \"notify_user_interest\":\n",
    "            result = notify_user_interest(**tool_arguments)\n",
    "        elif tool_name == \"notify_agent_failure\":\n",
    "            result = notify_agent_failure(**tool_arguments)\n",
    "        else:\n",
    "            unknown_tool_call = f\"Unknown tool call: {tool_name}\"\n",
    "            print(unknown_tool_call, flush=True)\n",
    "            result = unknown_tool_call \n",
    "\n",
    "        respond_to_agent_tool_calls.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(result),\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        })\n",
    "\n",
    "    return respond_to_agent_tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9761311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals() usage as an alternative to IF-ELSE above for cleaner code\n",
    "# globals() is a built-in Python function that returns a dictionary containing the current global namespace - \n",
    "# essentially all the variables, functions, and classes that are available in the current module (.py file).\n",
    "\n",
    "\"\"\"\n",
    "What globals() Includes:\n",
    "- Module-level variables\n",
    "- Module-level functions\n",
    "- Module-level classes\n",
    "- Built-in functions/variables\n",
    "- Imported modules\n",
    "\n",
    "What globals() Does NOT Include:\n",
    "- Class-level variables (class attributes)\n",
    "- Instance variables\n",
    "- Local variables inside functions\n",
    "- Variables inside classes\n",
    "\"\"\"\n",
    "\n",
    "globals()[\"notify_agent_failure\"](\"this is a really hard question\", \"I'm sorry, I can't answer that question.\")\n",
    "\n",
    "globals()[\"notify_user_interest\"](\"John Doe\", \"john@example.com\", \"I want to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79c1492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    - Problem: \n",
    "        globals() includes built-in functions. This could be dangerous - LLM could call ANY function!\n",
    "\n",
    "        below code:\n",
    "\n",
    "        malicious_function = \"os.system\"  # Could delete files!\n",
    "        if malicious_function in globals():\n",
    "            globals()[malicious_function](\"rm -rf /\")  # DANGEROUS!\n",
    "\n",
    "    - So, always make sure to allow only a specific list of tool functions to be called.\n",
    "    \"\"\"\n",
    "    \n",
    "    # This is a list of tool functions that are allowed to be called.\n",
    "    allowed_tool_functions = [\"notify_user_interest\", \"notify_agent_failure\"]\n",
    "\n",
    "    respond_to_agent_tool_calls = []\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        tool_arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: Name: {tool_name}, Arguments: {tool_arguments}\", flush=True)\n",
    "\n",
    "        if tool_name in allowed_tool_functions and tool_name in globals():\n",
    "            tool_function = globals()[tool_name]\n",
    "            result = tool_function(**tool_arguments)\n",
    "        else:\n",
    "            unknown_tool_call = f\"Unknown tool call: {tool_name}\"\n",
    "            print(unknown_tool_call, flush=True)\n",
    "            result = unknown_tool_call\n",
    "\n",
    "        respond_to_agent_tool_calls.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(result),\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        })\n",
    "\n",
    "    return respond_to_agent_tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa288559",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = \"Varun Kakuste\"\n",
    "first_name = \"Varun\"\n",
    "\n",
    "linkedIn_profile_text = \"\"\n",
    "\n",
    "linkedIn_Profile_pdf_reader = PdfReader(\"me/My_LinkedIn_Profile.pdf\")\n",
    "for page in linkedIn_Profile_pdf_reader.pages:\n",
    "    page_text = page.extract_text()\n",
    "    if page_text:\n",
    "        linkedIn_profile_text += page_text\n",
    "\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as summary_file:\n",
    "    summary_text = summary_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a39996",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"\n",
    "You are the professional AI Agent Avatar of {full_name}. You represent {first_name} on their personal website and respond on their behalf to visitors who may include hiring managers, investors, founders, recruiters, and other professionals.\n",
    "\n",
    "You have access to the following structured information:\n",
    "- LinkedIn Profile: {linkedIn_profile_text}\n",
    "- Summary/Bio: {summary_text}\n",
    "\n",
    "You are expected to respond in a tone that is:\n",
    "- Professional\n",
    "- Friendly\n",
    "- Authentic to {first_name}'s voice\n",
    "- Clear, concise, and context-aware\n",
    "\n",
    "Your role is to provide high-quality, truthful, and helpful responses using only the above knowledge. Do not guess or fabricate details.\n",
    "\n",
    "---\n",
    "\n",
    "### TOOL USAGE INSTRUCTIONS\n",
    "\n",
    "You have access to tools and may call them when appropriate:\n",
    "\n",
    "**1. Tool: `notify_user_interest`**\n",
    "- Use when the visitor expresses interest in contacting {first_name} (e.g., scheduling a call, asking how to connect, requesting to talk, etc.).\n",
    "- Do not use this tool for casual compliments or generic remarks.\n",
    "\n",
    "**2. Tool: `notify_agent_failure`**\n",
    "- Use notify_agent_failure whenever you are unable to answer the user’s question, and the question appears to be personal, private, sensitive, or not covered in the available information.\n",
    "- You must not guess or make up answers. If unsure, use this tool to alert {first_name} so he can follow up.\n",
    "- In addition but **not limited to** below, if the user asks about:\n",
    "    - Private career goals\n",
    "    - Salary, family, politics, or religion\n",
    "    - Deep technical details not in profile\n",
    "    You should call the **notify_agent_failure** tool.\n",
    "- Never make assumptions about {first_name}'s work authorization, immigration status, or other personal legal details. If a visitor asks about these topics, trigger the `notify_agent_failure` tool instead of responding directly.\n",
    "\n",
    "After using a tool, wait for the tool response before continuing the conversation. Do not continue unless the result of the tool call is available.\n",
    "\n",
    "---\n",
    "\n",
    "### SAFETY & FALLBACK BEHAVIOR\n",
    "\n",
    "- If you’re unsure of an answer, do **not fabricate** information. Instead, either politely decline to answer or trigger the `notify_agent_failure` tool.\n",
    "- Do not provide medical, legal, financial, or personal advice unless it is already present in the LinkedIn or summary data.\n",
    "- Avoid speculation about confidential topics like salary, political opinions, or personal relationships.\n",
    "\n",
    "---\n",
    "\n",
    "### FINAL GUIDELINES\n",
    "\n",
    "- Never refer to yourself as \"AI\" or \"Chatbot.\"\n",
    "- Always speak in the first person as if you are {first_name}.\n",
    "- Maintain trust, professionalism, and clarity in all interactions.\n",
    "\n",
    "You are a capable, intelligent digital assistant version of {first_name}, designed to create meaningful, respectful, and accurate professional interactions.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = system_prompt_template.format(\n",
    "    full_name=full_name,\n",
    "    first_name=first_name,\n",
    "    linkedIn_profile_text=linkedIn_profile_text,\n",
    "    summary_text=summary_text\n",
    ")\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b49d1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a simple question for openai\n",
    "\n",
    "# messages_to_agent = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"Are you a musician?\"}]\n",
    "\n",
    "# response = openai_client.chat.completions.create(\n",
    "#     model=openai_model_name,\n",
    "#     messages=messages_to_agent,\n",
    "#     tools=tool_spec\n",
    "# )\n",
    "\n",
    "# reply = response.choices[0].message.content\n",
    "# print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the agent with a simple question for gemini\n",
    "\n",
    "# messages_to_agent = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"Do you require Visa Sponsorship?\"}]\n",
    "\n",
    "# response = gemini_openai_client.chat.completions.create(\n",
    "#     model=gemini_model_name,\n",
    "#     messages=messages_to_agent,\n",
    "#     tools=tool_spec\n",
    "# )\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# reply = response.choices[0].message.content\n",
    "# print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a simple question for OpenAI model (gpt-4o-mini)\n",
    "\n",
    "def chat_with_agent_openai(user_prompt, history):\n",
    "    messages_to_agent = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    is_done = False\n",
    "    while not is_done:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=openai_model_name,\n",
    "            messages=messages_to_agent,\n",
    "            tools=tool_spec\n",
    "        )\n",
    "\n",
    "        # If the LLM/AI_Agent has finished its task, it will return a finish_reason object.\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            # We get the message object from the response\n",
    "            message = response.choices[0].message\n",
    "            # If the LLM/AI_Agent needs to call a tool, it will return a tool_calls object.\n",
    "            tool_calls = message.tool_calls\n",
    "            # We run the tool calls\n",
    "            tool_results = handle_tool_calls(tool_calls)\n",
    "            # We add the tool results to the messages_to_agent list\n",
    "            messages_to_agent.append(message)\n",
    "            messages_to_agent.extend(tool_results)\n",
    "        else:\n",
    "            is_done = True\n",
    "\n",
    "    agent_reply = response.choices[0].message.content\n",
    "    print(agent_reply)\n",
    "    messages_to_agent.append({\"role\": \"assistant\", \"content\": agent_reply})\n",
    "    return agent_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f380db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat_with_agent_openai, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "88f80e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a simple question for Gemini model (gemini-2.0-flash)\n",
    "\n",
    "def chat_with_agent_gemini(user_prompt, history):\n",
    "    messages_to_agent = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    is_done = False\n",
    "    while not is_done:\n",
    "        response = gemini_openai_client.chat.completions.create(\n",
    "            model=gemini_model_name,\n",
    "            messages=messages_to_agent,\n",
    "            tools=tool_spec\n",
    "        )\n",
    "\n",
    "        # If the LLM/AI_Agent has finished its task, it will return a finish_reason object.\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            # We get the message object from the response\n",
    "            message = response.choices[0].message\n",
    "            # If the LLM/AI_Agent needs to call a tool, it will return a tool_calls object.\n",
    "            tool_calls = message.tool_calls\n",
    "            # We run the tool calls\n",
    "            tool_results = handle_tool_calls(tool_calls)\n",
    "            # We add the tool results to the messages_to_agent list\n",
    "            messages_to_agent.append(message)\n",
    "            messages_to_agent.extend(tool_results)\n",
    "        else:\n",
    "            is_done = True\n",
    "\n",
    "    agent_reply = response.choices[0].message.content\n",
    "    print(agent_reply)\n",
    "    messages_to_agent.append({\"role\": \"assistant\", \"content\": agent_reply})\n",
    "    return agent_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat_with_agent_gemini, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
