{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e5e0ba",
   "metadata": {},
   "source": [
    "# How to use Guardrails? and Structured output\n",
    "\n",
    "We will implement a Guardrail to check if Name is present in the user_prompt, if so, it should fail otherwise pass and return structured output\n",
    "\n",
    "1. Input Guardrail\n",
    "2. Output Gaurdrail\n",
    "\n",
    "| Guardrail Type   | Purpose               | Example Trigger                 |\n",
    "| ---------------- | --------------------- | ------------------------------- |\n",
    "| Input Guardrail  | Before agent responds | User input contains banned name |\n",
    "| Output Guardrail | After agent responds  | Agent response includes a name  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "849c23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, trace, OpenAIChatCompletionsModel, input_guardrail, output_guardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered, OutputGuardrailTripwireTriggered\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "gemini_client = AsyncOpenAI(api_key=os.getenv(\"GEMINI_API_KEY\"), base_url=os.getenv(\"GEMINI_BASE_URL\"))\n",
    "\n",
    "gemini_model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "gemini_model = OpenAIChatCompletionsModel(openai_client=gemini_client, model=gemini_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a4ffb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGuardrailResponse(BaseModel):\n",
    "    is_name_present: bool\n",
    "    name: str\n",
    "    text: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc83d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameCheckGuardrailResponse(BaseModel):    \n",
    "    is_name_present: bool\n",
    "    name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "54db961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiResponseFormat(BaseModel):\n",
    "    is_name_present: bool\n",
    "    name: str\n",
    "    # Note: Below does not work with Gemini Model but works with OpenAI Model \n",
    "    # Error: BadRequestError: Error code: 400 \n",
    "    # - [{'error': {'code': 400, 'message': \"Unable to submit request because one or more response schemas didn't specify the schema type field.\n",
    "    \n",
    "    # name: str | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c773c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_check_guardrail_instructions = \"You are a guardrail agent that checks if the name is present in the user prompt. If it is, it should fail otherwise pass and return structured output.\"\n",
    "name_check_guardrail_agent = Agent(name=\"name_check_guardrail_agent\", instructions=name_check_guardrail_instructions, model=gemini_model, output_type=NameCheckGuardrailResponse)\n",
    "\n",
    "name_check_guardrail_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ff91d",
   "metadata": {},
   "source": [
    "# Input Guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8149edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@input_guardrail()\n",
    "async def name_check_guardrail_function(ctx, agent, user_prompt):\n",
    "    response = await Runner.run(name_check_guardrail_agent, user_prompt, context=ctx.context)\n",
    "    is_name_present_in_prompt = response.final_output.is_name_present\n",
    "    return GuardrailFunctionOutput(\n",
    "        tripwire_triggered=is_name_present_in_prompt,\n",
    "        output_info={\"found_name\": response.final_output.name}\n",
    "    )\n",
    "\n",
    "\n",
    "# print(name_check_guardrail_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3dc9504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gemini_model_agent = Agent(name=\"test_gemini_model_agent\", instructions=\"You are a test agent that uses the Gemini model to generate a response.\", model=gemini_model, output_type=TestGuardrailResponse, input_guardrails=[name_check_guardrail_function])\n",
    "\n",
    "user_prompt_with_name = \"Is Sundar Pichai your CEO?\"\n",
    "user_prompt_without_name = \"Is AI your CEO?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98913c11",
   "metadata": {},
   "source": [
    "### Below will fail with `InputGuardrailTripwireTriggered: Guardrail InputGuardrail triggered tripwire` error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below will fail with `InputGuardrailTripwireTriggered: Guardrail InputGuardrail triggered tripwire` error\n",
    "\n",
    "response_from_test_gemini_model_agent = await Runner.run(test_gemini_model_agent, user_prompt_with_name)\n",
    "\n",
    "print(response_from_test_gemini_model_agent.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee69765",
   "metadata": {},
   "source": [
    "### Customize Response Instead of Crashing with InputGuardrailTripwireTriggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eeecf029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Sorry, you can't mention personal names like 'Sundar Pichai' in this assistant.\n"
     ]
    }
   ],
   "source": [
    "# But Input Guardrail returns output_info as a dictionary, so we should error message instead of error stacktrace\n",
    "# Customize Response Instead of Crashing\n",
    "\n",
    "try:\n",
    "    user_prompt = \"Is Sundar Pichai your CEO?\"\n",
    "    response_from_test_gemini_model_agent = await Runner.run(test_gemini_model_agent, user_prompt)\n",
    "    print(response_from_test_gemini_model_agent.final_output)\n",
    "except InputGuardrailTripwireTriggered as e:\n",
    "    name_found_in_prompt = e.guardrail_result.output.output_info[\"found_name\"]\n",
    "    print(f\"ERROR: Sorry, you can't mention personal names like '{name_found_in_prompt}' in this assistant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9a34d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_name_present=False name='AI' text='I am a large language model, trained by Google. I am developed to be informative and comprehensive. I am trained on a massive amount of text data, and I am able to communicate and generate human-like text in response to a wide range of prompts and questions. However, I do not have a CEO.'\n"
     ]
    }
   ],
   "source": [
    "# Working user_prompt which doesn't have name in it\n",
    "\n",
    "response_from_test_gemini_model_agent = await Runner.run(test_gemini_model_agent, user_prompt_without_name)\n",
    "\n",
    "print(response_from_test_gemini_model_agent.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3906e",
   "metadata": {},
   "source": [
    "# Output Gaurdrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5224a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfanityCheckGuardrailResponse(BaseModel):\n",
    "    is_profanity_present: bool\n",
    "    profanity: str\n",
    "    text: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8ecad9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent(name='profanity_check_guardrail_agent', handoff_description=None, tools=[], mcp_servers=[], mcp_config={}, instructions='You are a guardrail agent that checks if the profanity is present in the user prompt. If it is, it should fail otherwise pass and return structured output.', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x116494080>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, response_include=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=<class '__main__.ProfanityCheckGuardrailResponse'>, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
     ]
    }
   ],
   "source": [
    "profanity_check_guardrail_instructions = \"You are a guardrail agent that checks if the profanity is present in the user prompt. If it is, it should fail otherwise pass and return structured output.\"\n",
    "profanity_check_guardrail_agent = Agent(\n",
    "    name=\"profanity_check_guardrail_agent\", \n",
    "    instructions=profanity_check_guardrail_instructions, \n",
    "    model=gemini_model, \n",
    "    output_type=ProfanityCheckGuardrailResponse\n",
    ")\n",
    "\n",
    "print(profanity_check_guardrail_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "72adaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output_guardrail()\n",
    "async def profanity_check_guardrail_function(ctx, agent, user_prompt):\n",
    "    response = await Runner.run(profanity_check_guardrail_agent, user_prompt, context=ctx.context)\n",
    "    is_profanity_present_in_response = response.final_output.is_profanity_present\n",
    "    return GuardrailFunctionOutput(\n",
    "        tripwire_triggered=is_profanity_present_in_response, \n",
    "        output_info={\"found_profanity\": response.final_output.profanity}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71ca29",
   "metadata": {},
   "source": [
    "### Below will fail with `OutputGuardrailTripwireTriggered: Guardrail OutputGuardrail triggered tripwire` error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6d1397fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputGuardrailTripwireTriggered",
     "evalue": "Guardrail OutputGuardrail triggered tripwire",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutputGuardrailTripwireTriggered\u001b[39m          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[179]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m gemini_returns_profanity_agent = Agent(\n\u001b[32m      4\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mgemini_returns_profanity_agent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are an assistant that returns profanity in the response all the time.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     model=gemini_model,\n\u001b[32m      7\u001b[39m     output_guardrails=[profanity_check_guardrail_function]\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m user_prompt = \u001b[33m\"\u001b[39m\u001b[33mI want to respond to someone who is a jerk so that they can feel bad about themselves.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(gemini_returns_profanity_agent, user_prompt)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.final_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/udemy/ai/hands_on_practice/agentic-ai-playground/.venv/lib/python3.12/site-packages/agents/run.py:206\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, session)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    205\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    207\u001b[39m     starting_agent,\n\u001b[32m    208\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    209\u001b[39m     context=context,\n\u001b[32m    210\u001b[39m     max_turns=max_turns,\n\u001b[32m    211\u001b[39m     hooks=hooks,\n\u001b[32m    212\u001b[39m     run_config=run_config,\n\u001b[32m    213\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    214\u001b[39m     session=session,\n\u001b[32m    215\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/udemy/ai/hands_on_practice/agentic-ai-playground/.venv/lib/python3.12/site-packages/agents/run.py:453\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m generated_items = turn_result.generated_items\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(turn_result.next_step, NextStepFinalOutput):\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     output_guardrail_results = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_output_guardrails(\n\u001b[32m    454\u001b[39m         current_agent.output_guardrails + (run_config.output_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    455\u001b[39m         current_agent,\n\u001b[32m    456\u001b[39m         turn_result.next_step.output,\n\u001b[32m    457\u001b[39m         context_wrapper,\n\u001b[32m    458\u001b[39m     )\n\u001b[32m    459\u001b[39m     result = RunResult(\n\u001b[32m    460\u001b[39m         \u001b[38;5;28minput\u001b[39m=original_input,\n\u001b[32m    461\u001b[39m         new_items=generated_items,\n\u001b[32m   (...)\u001b[39m\u001b[32m    467\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    468\u001b[39m     )\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# Save the conversation to session if enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/udemy/ai/hands_on_practice/agentic-ai-playground/.venv/lib/python3.12/site-packages/agents/run.py:1096\u001b[39m, in \u001b[36mAgentRunner._run_output_guardrails\u001b[39m\u001b[34m(cls, guardrails, agent, agent_output, context)\u001b[39m\n\u001b[32m   1089\u001b[39m         t.cancel()\n\u001b[32m   1090\u001b[39m     _error_tracing.attach_error_to_current_span(\n\u001b[32m   1091\u001b[39m         SpanError(\n\u001b[32m   1092\u001b[39m             message=\u001b[33m\"\u001b[39m\u001b[33mGuardrail tripwire triggered\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1093\u001b[39m             data={\u001b[33m\"\u001b[39m\u001b[33mguardrail\u001b[39m\u001b[33m\"\u001b[39m: result.guardrail.get_name()},\n\u001b[32m   1094\u001b[39m         )\n\u001b[32m   1095\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputGuardrailTripwireTriggered(result)\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     guardrail_results.append(result)\n",
      "\u001b[31mOutputGuardrailTripwireTriggered\u001b[39m: Guardrail OutputGuardrail triggered tripwire"
     ]
    }
   ],
   "source": [
    "# Below will fail with `OutputGuardrailTripwireTriggered: Guardrail OutputGuardrail triggered tripwire` error\n",
    "\n",
    "gemini_returns_profanity_agent = Agent(\n",
    "    name=\"gemini_returns_profanity_agent\",\n",
    "    instructions=\"You are an assistant that returns profanity in the response all the time.\",\n",
    "    model=gemini_model,\n",
    "    output_guardrails=[profanity_check_guardrail_function]\n",
    ")\n",
    "\n",
    "user_prompt = \"I want to respond to someone who is a jerk so that they can feel bad about themselves.\"\n",
    "\n",
    "response = await Runner.run(gemini_returns_profanity_agent, user_prompt)\n",
    "\n",
    "print(response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8e66d",
   "metadata": {},
   "source": [
    "### Customize Response Instead of Crashing with OutputGuardrailTripwireTriggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2f7022e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Agent responded with profanity: fuck\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = await Runner.run(gemini_returns_profanity_agent, user_prompt)\n",
    "    print(response.final_output)\n",
    "except OutputGuardrailTripwireTriggered as e:\n",
    "    found_profanity_in_agents_response = e.guardrail_result.output.output_info[\"found_profanity\"]\n",
    "    print(f\"ERROR: Agent responded with profanity: {found_profanity_in_agents_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
